{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nCNN-for-classifying-letters\nBy: Sedki Ltifi\n"},{"metadata":{},"cell_type":"markdown","source":"here we'll build a Conv2d to be used in reading & classifying about half million pictures of first 10 alphabetic letters . .\n\nyou can find data file here : https://www.kaggle.com/jwjohnson314/notmnist\n\nlet;s first import libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport keras\nimport os\nimport glob as gb\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten ,Conv2D, MaxPooling2D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then we need to check the folders to know what letters available .\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_letters = os.listdir('../input/notmnist/notMNIST_large/notMNIST_large')\n\nprint(f'We have {len(all_letters)} letters , which are : {all_letters}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data ."},{"metadata":{},"cell_type":"markdown","source":"we'll use glob library to collect all png pictures to know how many pictures we have for each letter .\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_images = 0\nfor letter in all_letters : \n    available_images = gb.glob(pathname= f'../input/notmnist/notMNIST_large/notMNIST_large/{letter}/*.png')\n    total_images+=len(available_images)\n    print(f'for letter {letter} we have  {len(available_images)} available images')\nprint('-----------------------')    \nprint(f'Total Images are {total_images} images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"total 529 thousand images for all 10 letters , now let's create X & y variables , so we can fill them with read data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = list(np.zeros(shape=(total_images , 28,28)))\ny = list(np.zeros(shape=(total_images)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now to open each file & read it using plt.imread , then fill it in its place in X & y data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\ny_value = 0\nfor letter in all_letters : \n    available_images = gb.glob(pathname= f'../input/notmnist/notMNIST_large/notMNIST_large/{letter}/*.png')\n    for image in available_images : \n        try : \n            x = plt.imread(image)\n            X[i] = x\n            y[i] = y_value\n            i+=1\n        except : \n            pass\n    y_value+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forming Dimensions"},{"metadata":{},"cell_type":"markdown","source":"since (y) data now is a single number vary from 0 to 9 , we'll need to categorize it using OneHotEncoder from sklearn , so it be ready for the softmax activation functing in CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe  = OneHotEncoder()\ny = np.array(y)\ny = y.reshape(len(y), 1)\nohe.fit(y)\ny = ohe.transform(y).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we can check a random y value"},{"metadata":{"trusted":true},"cell_type":"code","source":"y[10000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then we have to expand X dimension to be suitable with the CNN dimensions\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.expand_dims(X, -1).astype('float32')/255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now X shape should be : sample size 28 28 * 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data"},{"metadata":{},"cell_type":"markdown","source":"now lets split our dat to Train , Cross-Validation & Test sets . .\n\nfirst to create X_part & y_part which is 85% of data , also X_test & y_test which is 15%"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_part, X_cv, y_part, y_cv = train_test_split(X, y, test_size=0.15, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_part.shape)\nprint('X_test shape is ' , X_cv.shape)\nprint('y_train shape is ' , y_part.shape)\nprint('y_test shape is ' , y_cv.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then to split X_part & y_part into train & test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_part, y_part, test_size=0.25, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build the Model"},{"metadata":{},"cell_type":"markdown","source":"now let's build the model with Keras , using Conv2d & Maxpooling tools , & not to forget to dropout some cells to avoid OF\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"KerasModel = keras.models.Sequential([\n        keras.layers.Conv2D(filters = 32, kernel_size = 4,  activation = tf.nn.relu , padding = 'same'),\n        keras.layers.MaxPool2D(pool_size=(3,3), strides=None, padding='valid'),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2D(filters=32, kernel_size=4,activation = tf.nn.relu , padding='same'),\n        keras.layers.MaxPool2D(),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2D(filters=64, kernel_size=5,activation = tf.nn.relu , padding='same'),\n        keras.layers.MaxPool2D(),\n        keras.layers.Flatten(),    \n        keras.layers.Dropout(0.5),        \n        keras.layers.Dense(64),    \n        keras.layers.Dropout(0.3),            \n        keras.layers.Dense(units= 10,activation = tf.nn.softmax ),                \n\n    ])\n    \n\nKerasModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then to train it , using few number of epochs to avoid OF"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train\nKerasModel.fit(X_train,y_train,validation_data=(X_cv, y_cv),epochs=3,batch_size=64,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now how the model looks like ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"KerasModel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting"},{"metadata":{},"cell_type":"markdown","source":"then we'll predict X_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = KerasModel.predict(X_test)\n\nprint('Prediction Shape is {}'.format(y_pred.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and we can check random samples from X_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"Letters ={0:'A', 1:'B' , 2:'C' ,3:'D' ,4:'E' ,5:'F' ,6:'G' ,7:'H' ,8:'I' ,9:'J' }\n\nfor i in list(np.random.randint(0,len(X_test) ,size= 10)) : \n    print(f'for sample  {i}  the predicted value is   {Letters[np.argmax(y_pred[i])]}   , while the actual letter is {Letters[np.argmax(y_test[i])]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"& to measure the loss & accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nModelLoss, ModelAccuracy = KerasModel.evaluate(X_test, y_test)\n\nprint('Test Loss is {}'.format(ModelLoss))\nprint('Test Accuracy is {}'.format(ModelAccuracy ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , with 91% accuracy we achieved good result without moving to OF"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}